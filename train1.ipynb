{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 1503657984 bytes (4603804318 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/ibrahimalobaid/kitte-dataset?dataset_version_number=1 (1503657984/6107462302) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.69G/5.69G [04:32<00:00, 16.9MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/ibrahimalobaid/kitte-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ibrahimalobaid/kitte-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ KITTI to YOLO conversion completed for class 'Car'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "kitti_base_path = 'training'\n",
    "yolo_base_path = 'data/kitti-yolo'\n",
    "\n",
    "images_path = os.path.join(kitti_base_path, 'image_2')\n",
    "labels_path = os.path.join(kitti_base_path, 'label_2')\n",
    "yolo_images_path = os.path.join(yolo_base_path, 'images')\n",
    "yolo_labels_path = os.path.join(yolo_base_path, 'labels')\n",
    "\n",
    "# Make YOLO folders\n",
    "os.makedirs(yolo_images_path, exist_ok=True)\n",
    "os.makedirs(yolo_labels_path, exist_ok=True)\n",
    "\n",
    "# We only keep this class\n",
    "target_class = 'Car'\n",
    "class_id = 0  # YOLO class index for 'Car'\n",
    "\n",
    "# Converts KITTI bbox (xmin, ymin, xmax, ymax) to YOLO bbox (cx, cy, w, h)\n",
    "def convert_bbox(size, box):\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    x_center = (box[0] + box[2]) / 2.0\n",
    "    y_center = (box[1] + box[3]) / 2.0\n",
    "    width = box[2] - box[0]\n",
    "    height = box[3] - box[1]\n",
    "    return (x_center * dw, y_center * dh, width * dw, height * dh)\n",
    "\n",
    "# Process each label file\n",
    "for label_file in os.listdir(labels_path):\n",
    "    if not label_file.endswith('.txt'):\n",
    "        continue\n",
    "\n",
    "    image_file = label_file.replace('.txt', '.png')\n",
    "    image_path = os.path.join(images_path, image_file)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"‚ö†Ô∏è Image not found: {image_file}\")\n",
    "        continue\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"‚ö†Ô∏è Could not read image: {image_file}\")\n",
    "        continue\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # Read KITTI label file\n",
    "    with open(os.path.join(labels_path, label_file), 'r') as lf:\n",
    "        lines = lf.readlines()\n",
    "\n",
    "    yolo_label_lines = []\n",
    "    for line in lines:\n",
    "        elements = line.strip().split()\n",
    "\n",
    "        if elements[0] != target_class:\n",
    "            continue  # only use 'Car' class\n",
    "\n",
    "        # Extract and convert bounding box\n",
    "        xmin = float(elements[4])\n",
    "        ymin = float(elements[5])\n",
    "        xmax = float(elements[6])\n",
    "        ymax = float(elements[7])\n",
    "\n",
    "        bbox = convert_bbox((w, h), (xmin, ymin, xmax, ymax))\n",
    "        yolo_line = f\"{class_id} {' '.join(f'{b:.6f}' for b in bbox)}\\n\"\n",
    "        yolo_label_lines.append(yolo_line)\n",
    "\n",
    "    # Skip if no 'Car' objects in image\n",
    "    if not yolo_label_lines:\n",
    "        continue\n",
    "\n",
    "    # Write YOLO label file\n",
    "    with open(os.path.join(yolo_labels_path, label_file), 'w') as yf:\n",
    "        yf.writelines(yolo_label_lines)\n",
    "\n",
    "    # Copy image to YOLO images directory\n",
    "    shutil.copy(image_path, os.path.join(yolo_images_path, image_file))\n",
    "\n",
    "print(\"‚úÖ KITTI to YOLO conversion completed for class 'Car'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tqdm\n",
    "# === INPUT PATHS ===\n",
    "input_images_base = 'UA-DETRAC_UPD_ANN/images'  # Images (JPG/PNG)\n",
    "input_labels_base = 'UA-DETRAC_UPD_ANN/labels'  # YOLO labels (.txt)\n",
    "\n",
    "# === OUTPUT PATHS ===\n",
    "output_base = 'data/ua-detrac'\n",
    "output_images_base = os.path.join(output_base, 'images')\n",
    "output_labels_base = os.path.join(output_base, 'labels')\n",
    "\n",
    "# === Make output directories ===\n",
    "os.makedirs(output_images_base, exist_ok=True)\n",
    "os.makedirs(output_labels_base, exist_ok=True)\n",
    "\n",
    "# === Class ID for 'car' in UA-DETRAC ===\n",
    "CAR_CLASS_ID = '2'\n",
    "\n",
    "# === Process both splits: train and val ===\n",
    "for split in ['train', 'val']:\n",
    "    in_img_dir = os.path.join(input_images_base, split)\n",
    "    in_lbl_dir = os.path.join(input_labels_base, split)\n",
    "    out_img_dir = os.path.join(output_images_base, split)\n",
    "    out_lbl_dir = os.path.join(output_labels_base, split)\n",
    "\n",
    "    # Create output directories\n",
    "    os.makedirs(out_img_dir, exist_ok=True)\n",
    "    os.makedirs(out_lbl_dir, exist_ok=True)\n",
    "\n",
    "    for lbl_file in os.listdir(in_lbl_dir):\n",
    "        if not lbl_file.endswith('.txt'):\n",
    "            continue\n",
    "\n",
    "        input_lbl_path = os.path.join(in_lbl_dir, lbl_file)\n",
    "        with open(input_lbl_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Filter only lines with class ID 3 (car)\n",
    "        car_lines = [line for line in lines if line.strip().split()[0] == CAR_CLASS_ID]\n",
    "\n",
    "        if not car_lines:\n",
    "            continue  # Skip if no cars\n",
    "\n",
    "        # Save filtered label\n",
    "        output_lbl_path = os.path.join(out_lbl_dir, lbl_file)\n",
    "        with open(output_lbl_path, 'w') as f:\n",
    "            f.writelines(car_lines)\n",
    "\n",
    "        # Copy corresponding image\n",
    "        img_file = lbl_file.replace('.txt', '.jpg')  # or '.png' if your images are PNG\n",
    "        input_img_path = os.path.join(in_img_dir, img_file)\n",
    "        output_img_path = os.path.join(out_img_dir, img_file)\n",
    "\n",
    "        if os.path.exists(input_img_path):\n",
    "            shutil.copy(input_img_path, output_img_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Image missing for: {img_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# === Base paths ===\n",
    "kitti_base = 'data/kitti-yolo'\n",
    "img_dir = os.path.join(kitti_base, 'images')\n",
    "lbl_dir = os.path.join(kitti_base, 'labels')\n",
    "\n",
    "# === Output paths ===\n",
    "splits = ['train', 'val']\n",
    "output_dirs = {\n",
    "    'train': {\n",
    "        'images': os.path.join(kitti_base, 'images/train'),\n",
    "        'labels': os.path.join(kitti_base, 'labels/train')\n",
    "    },\n",
    "    'val': {\n",
    "        'images': os.path.join(kitti_base, 'images/val'),\n",
    "        'labels': os.path.join(kitti_base, 'labels/val')\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Create output folders ===\n",
    "for split in splits:\n",
    "    os.makedirs(output_dirs[split]['images'], exist_ok=True)\n",
    "    os.makedirs(output_dirs[split]['labels'], exist_ok=True)\n",
    "\n",
    "# === Split logic ===\n",
    "image_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(image_files) * split_ratio)\n",
    "\n",
    "split_map = {\n",
    "    img: 'train' if i < split_index else 'val'\n",
    "    for i, img in enumerate(image_files)\n",
    "}\n",
    "\n",
    "# === Move files ===\n",
    "for img_file, split in split_map.items():\n",
    "    label_file = img_file.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "\n",
    "    src_img = os.path.join(img_dir, img_file)\n",
    "    src_lbl = os.path.join(lbl_dir, label_file)\n",
    "\n",
    "    dst_img = os.path.join(output_dirs[split]['images'], img_file)\n",
    "    dst_lbl = os.path.join(output_dirs[split]['labels'], label_file)\n",
    "\n",
    "    shutil.copy2(src_img, dst_img)\n",
    "    if os.path.exists(src_lbl):\n",
    "        shutil.copy2(src_lbl, dst_lbl)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Label not found for image {img_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# === Source dataset paths ===\n",
    "datasets = [\n",
    "    'data/kitti-yolo',\n",
    "    'data/ua-detrac'\n",
    "]\n",
    "\n",
    "# === Destination merged dataset ===\n",
    "combined_base = 'data/combined_data'\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    combined_img_dir = os.path.join(combined_base, 'images', split)\n",
    "    combined_lbl_dir = os.path.join(combined_base, 'labels', split)\n",
    "    os.makedirs(combined_img_dir, exist_ok=True)\n",
    "    os.makedirs(combined_lbl_dir, exist_ok=True)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        src_img_dir = os.path.join(dataset, 'images', split)\n",
    "        src_lbl_dir = os.path.join(dataset, 'labels', split)\n",
    "\n",
    "        for img_file in os.listdir(src_img_dir):\n",
    "            src_img_path = os.path.join(src_img_dir, img_file)\n",
    "            dst_img_path = os.path.join(combined_img_dir, img_file)\n",
    "            shutil.copy2(src_img_path, dst_img_path)\n",
    "\n",
    "        for lbl_file in os.listdir(src_lbl_dir):\n",
    "            src_lbl_path = os.path.join(src_lbl_dir, lbl_file)\n",
    "            dst_lbl_path = os.path.join(combined_lbl_dir, lbl_file)\n",
    "            shutil.copy2(src_lbl_path, dst_lbl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "label_root = 'data/combined_data/labels'\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    label_dir = os.path.join(label_root, split)\n",
    "    for file in os.listdir(label_dir):\n",
    "        if not file.endswith('.txt'):\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(label_dir, file)\n",
    "\n",
    "        with open(path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        fixed_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue  # skip malformed lines\n",
    "\n",
    "            # force class ID to 0\n",
    "            fixed_line = '0 ' + ' '.join(parts[1:]) + '\\n'\n",
    "            fixed_lines.append(fixed_line)\n",
    "\n",
    "        # overwrite label file\n",
    "        with open(path, 'w') as f:\n",
    "            f.writelines(fixed_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset looks good! No issues found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def validate_yolo_dataset(dataset_path, nc=1):\n",
    "    \"\"\"\n",
    "    dataset_path: path to combined YOLO dataset (with images/train, labels/train, etc.)\n",
    "    nc: number of classes (e.g., 1 for 'car' only)\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for split in ['train', 'val']:\n",
    "        img_dir = os.path.join(dataset_path, 'images', split)\n",
    "        lbl_dir = os.path.join(dataset_path, 'labels', split)\n",
    "\n",
    "        if not os.path.isdir(img_dir) or not os.path.isdir(lbl_dir):\n",
    "            errors.append(f\"‚ùå Missing directory for split {split}\")\n",
    "            continue\n",
    "\n",
    "        img_files = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "        for img_file in img_files:\n",
    "            lbl_file = img_file.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "            lbl_path = os.path.join(lbl_dir, lbl_file)\n",
    "\n",
    "            if not os.path.exists(lbl_path):\n",
    "                errors.append(f\"‚ùå Missing label for image: {split}/{img_file}\")\n",
    "                continue\n",
    "\n",
    "            with open(lbl_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            if len(lines) == 0:\n",
    "                errors.append(f\"‚ö†Ô∏è Empty label file: {split}/{lbl_file}\")\n",
    "                continue\n",
    "\n",
    "            for idx, line in enumerate(lines):\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    errors.append(f\"‚ùå Invalid line format in {split}/{lbl_file}: '{line.strip()}'\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    cls_id = int(parts[0])\n",
    "                    if not (0 <= cls_id < nc):\n",
    "                        errors.append(f\"‚ùå Invalid class ID {cls_id} in {split}/{lbl_file}\")\n",
    "                    bbox = list(map(float, parts[1:]))\n",
    "                    if not all(0 <= x <= 1 for x in bbox):\n",
    "                        errors.append(f\"‚ùå Bounding box out of range in {split}/{lbl_file}: {bbox}\")\n",
    "                except ValueError:\n",
    "                    errors.append(f\"‚ùå Non-numeric value in {split}/{lbl_file}: '{line.strip()}'\")\n",
    "\n",
    "    # Print summary\n",
    "    if errors:\n",
    "        print(f\"üîç Found {len(errors)} issues in dataset:\\n\")\n",
    "        for e in errors[:50]:  # only show first 50 errors\n",
    "            print(e)\n",
    "        if len(errors) > 50:\n",
    "            print(f\"... (and {len(errors) - 50} more)\")\n",
    "    else:\n",
    "        print(\"‚úÖ Dataset looks good! No issues found.\")\n",
    "\n",
    "# === Run this ===\n",
    "validate_yolo_dataset('data/combined_data', nc=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='n'.\n",
      "Ultralytics 8.3.156 üöÄ Python-3.10.12 torch-2.7.1+cu126 CUDA:1 (NVIDIA H100 80GB HBM3 MIG 3g.40gb, 40320MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8-ghost-p2.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8-ghostp2-optimized3, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train-ghost, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/train-ghost/yolov8-ghostp2-optimized3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      2768  ultralytics.nn.modules.conv.GhostConv        [16, 32, 3, 2]                \n",
      "  2                  -1  1      2652  ultralytics.nn.modules.block.C3Ghost         [32, 32, 1, True]             \n",
      "  3                  -1  1     10144  ultralytics.nn.modules.conv.GhostConv        [32, 64, 3, 2]                \n",
      "  4                  -1  2     10864  ultralytics.nn.modules.block.C3Ghost         [64, 64, 2, True]             \n",
      "  5                  -1  1     38720  ultralytics.nn.modules.conv.GhostConv        [64, 128, 3, 2]               \n",
      "  6                  -1  2     40160  ultralytics.nn.modules.block.C3Ghost         [128, 128, 2, True]           \n",
      "  7                  -1  1    151168  ultralytics.nn.modules.conv.GhostConv        [128, 256, 3, 2]              \n",
      "  8                  -1  1    143072  ultralytics.nn.modules.block.C3Ghost         [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1     69488  ultralytics.nn.modules.block.C3Ghost         [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     17848  ultralytics.nn.modules.block.C3Ghost         [192, 64, 1]                  \n",
      " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 17             [-1, 2]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1      4700  ultralytics.nn.modules.block.C3Ghost         [96, 32, 1]                   \n",
      " 19                  -1  1      5072  ultralytics.nn.modules.conv.GhostConv        [32, 32, 3, 2]                \n",
      " 20            [-1, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1     11704  ultralytics.nn.modules.block.C3Ghost         [96, 64, 1]                   \n",
      " 22                  -1  1     19360  ultralytics.nn.modules.conv.GhostConv        [64, 64, 3, 2]                \n",
      " 23            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  1     44912  ultralytics.nn.modules.block.C3Ghost         [192, 128, 1]                 \n",
      " 25                  -1  1     75584  ultralytics.nn.modules.conv.GhostConv        [128, 128, 3, 2]              \n",
      " 26             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  1    175840  ultralytics.nn.modules.block.C3Ghost         [384, 256, 1]                 \n",
      " 28    [18, 21, 24, 27]  1    617364  ultralytics.nn.modules.head.Detect           [1, [32, 64, 128, 256]]       \n",
      "YOLOv8-ghost-p2 summary: 290 layers, 1,606,492 parameters, 1,606,476 gradients, 8.8 GFLOPs\n",
      "\n",
      "Freezing layer 'model.28.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 157.7¬±110.4 MB/s, size: 215.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/hjs/python/data/combined_data/labels/train... 41491 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41491/41491 [00:23<00:00, 1740.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /workspace/hjs/python/data/combined_data/labels/train.cache\n",
      "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (25.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41491/41491 [00:21<00:00, 1916.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.1 ms, read: 450.8¬±371.4 MB/s, size: 221.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/hjs/python/data/combined_data/labels/val.cache... 6675 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6675/6675 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.9GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6675/6675 [00:03<00:00, 1724.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/train-ghost/yolov8-ghostp2-optimized3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 111 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-ghost/yolov8-ghostp2-optimized3\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/200      9.08G      2.178       2.51      1.986         76        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:33<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:14<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.306      0.338      0.257      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/200      9.08G      1.461      1.553      1.418         73        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:28<00:00,  6.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.636       0.52      0.577      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/200      9.08G      1.295      1.301      1.291         89        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693       0.68      0.547      0.616      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/200      9.08G      1.202      1.153      1.224         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.653      0.509      0.567      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/200      9.08G      1.138      1.052      1.177         93        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.693      0.582      0.654      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/200      9.08G      1.091     0.9893      1.147         74        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.749      0.622      0.697      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/200      9.08G      1.066     0.9494      1.128         99        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.731      0.639      0.709      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/200      9.08G      1.037     0.9119      1.109         61        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.792      0.663      0.743      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/200       9.7G      1.018     0.8805      1.098         86        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.796      0.674      0.754      0.554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/200       9.7G      1.002     0.8583      1.086         92        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.795      0.672      0.751      0.551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/200       9.7G     0.9862     0.8344      1.076         80        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.816       0.68      0.762      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/200       9.7G     0.9674     0.8095      1.064         82        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.832      0.676      0.769      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/200      10.4G      0.963     0.8012       1.06         81        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693       0.82      0.662      0.764       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/200      10.4G     0.9491     0.7853      1.052         82        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.827      0.682       0.77      0.577\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/200      10.4G     0.9388     0.7708      1.047         71        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.828      0.696      0.779      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/200      10.4G     0.9341     0.7627      1.044        111        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.839      0.696      0.781      0.587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/200      10.4G     0.9235     0.7477      1.039         85        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.846      0.683      0.774      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/200      10.4G     0.9176     0.7375      1.036         73        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.837      0.685      0.776      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/200      10.4G     0.9093     0.7295      1.029         82        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:12<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.844      0.682      0.779      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/200      10.4G     0.9037     0.7224      1.027         86        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:21<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.845      0.687      0.783      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/200      10.4G     0.8987     0.7131      1.024         81        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.847      0.695      0.785      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/200      10.4G     0.8896     0.7023      1.017         70        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:21<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.848      0.691      0.784      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/200      10.4G     0.8879     0.6985      1.019         75        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.848      0.699      0.788      0.602\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/200      10.4G     0.8823     0.6931      1.014         75        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:21<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.854      0.699       0.79      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/200      10.4G     0.8794     0.6873      1.013         62        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [03:22<00:00,  6.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:11<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693       0.85      0.705      0.793      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/200      10.4G     0.8741     0.6807      1.009        107        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [05:38<00:00,  3.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:49<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.852      0.704      0.793      0.608\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/200      10.4G       0.87     0.6776      1.007        113        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [05:39<00:00,  3.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 100/105 [02:05<00:08,  1.67s/it]"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8-ghost-p2.yaml')  \n",
    "model.train(\n",
    "    data='data.yaml',     \n",
    "    epochs=200,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    cos_lr=True,\n",
    "    warmup_epochs=3,\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    "    copy_paste=0.1,\n",
    "    workers=8,\n",
    "    device=1,   # Change to 'cpu' if needed\n",
    "    patience=10,\n",
    "    project='runs/train-ghost',\n",
    "    name='yolov8-ghostp2-optimized',\n",
    "    save=True,\n",
    "    cache=True,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.158 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.156 üöÄ Python-3.10.12 torch-2.7.1+cu126 CUDA:1 (NVIDIA H100 80GB HBM3 MIG 3g.40gb, 40320MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=runs/train-ghost/yolov8-ghostp2-optimized3/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8-ghostp2-optimized3, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train-ghost, rect=False, resume=runs/train-ghost/yolov8-ghostp2-optimized3/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/train-ghost/yolov8-ghostp2-optimized3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      2768  ultralytics.nn.modules.conv.GhostConv        [16, 32, 3, 2]                \n",
      "  2                  -1  1      2652  ultralytics.nn.modules.block.C3Ghost         [32, 32, 1, True]             \n",
      "  3                  -1  1     10144  ultralytics.nn.modules.conv.GhostConv        [32, 64, 3, 2]                \n",
      "  4                  -1  2     10864  ultralytics.nn.modules.block.C3Ghost         [64, 64, 2, True]             \n",
      "  5                  -1  1     38720  ultralytics.nn.modules.conv.GhostConv        [64, 128, 3, 2]               \n",
      "  6                  -1  2     40160  ultralytics.nn.modules.block.C3Ghost         [128, 128, 2, True]           \n",
      "  7                  -1  1    151168  ultralytics.nn.modules.conv.GhostConv        [128, 256, 3, 2]              \n",
      "  8                  -1  1    143072  ultralytics.nn.modules.block.C3Ghost         [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1     69488  ultralytics.nn.modules.block.C3Ghost         [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     17848  ultralytics.nn.modules.block.C3Ghost         [192, 64, 1]                  \n",
      " 16                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 17             [-1, 2]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1      4700  ultralytics.nn.modules.block.C3Ghost         [96, 32, 1]                   \n",
      " 19                  -1  1      5072  ultralytics.nn.modules.conv.GhostConv        [32, 32, 3, 2]                \n",
      " 20            [-1, 15]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1     11704  ultralytics.nn.modules.block.C3Ghost         [96, 64, 1]                   \n",
      " 22                  -1  1     19360  ultralytics.nn.modules.conv.GhostConv        [64, 64, 3, 2]                \n",
      " 23            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  1     44912  ultralytics.nn.modules.block.C3Ghost         [192, 128, 1]                 \n",
      " 25                  -1  1     75584  ultralytics.nn.modules.conv.GhostConv        [128, 128, 3, 2]              \n",
      " 26             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  1    175840  ultralytics.nn.modules.block.C3Ghost         [384, 256, 1]                 \n",
      " 28    [18, 21, 24, 27]  1    617364  ultralytics.nn.modules.head.Detect           [1, [32, 64, 128, 256]]       \n",
      "YOLOv8-ghost-p2 summary: 290 layers, 1,606,492 parameters, 1,606,476 gradients, 8.8 GFLOPs\n",
      "\n",
      "Transferred 683/683 items from pretrained weights\n",
      "Freezing layer 'model.28.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 690.8¬±833.1 MB/s, size: 215.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/hjs/python/data/combined_data/labels/train.cache... 41491 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41491/41491 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (25.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41491/41491 [00:19<00:00, 2101.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.1 ms, read: 530.8¬±575.3 MB/s, size: 221.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/hjs/python/data/combined_data/labels/val.cache... 6675 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6675/6675 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.9GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6675/6675 [00:03<00:00, 1892.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/train-ghost/yolov8-ghostp2-optimized3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 111 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
      "Resuming training runs/train-ghost/yolov8-ghostp2-optimized3/weights/last.pt from epoch 49 to 200 total epochs\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-ghost/yolov8-ghostp2-optimized3\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/200      9.08G     0.8349     0.6321      0.992         76        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:21<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:17<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.847      0.728      0.806      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/200      9.08G     0.8366     0.6347     0.9911         73        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:16<00:00,  3.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:18<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.847      0.727      0.806       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/200      9.08G     0.8368     0.6358      0.991         89        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:18<00:00,  3.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:11<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.849      0.726      0.806       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/200      9.08G     0.8344     0.6328     0.9897         88        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:20<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:09<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.851      0.725      0.805       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/200      9.08G     0.8328     0.6297     0.9884         93        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:21<00:00,  3.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:13<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.848      0.728      0.805       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/200      9.08G     0.8273     0.6262     0.9858         74        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:20<00:00,  3.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:18<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.848      0.728      0.805       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/200      9.08G     0.8306     0.6284     0.9878         99        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:17<00:00,  3.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:18<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693       0.85      0.725      0.805       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/200      9.08G     0.8266     0.6228     0.9842         61        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:19<00:00,  3.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:10<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.852      0.723      0.805       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/200       9.7G     0.8237     0.6221     0.9842         86        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:22<00:00,  3.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [00:16<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.852      0.724      0.804       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/200       9.7G     0.8236     0.6182     0.9831         92        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [05:49<00:00,  3.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:18<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693       0.85      0.725      0.804       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/200       9.7G     0.8199     0.6153     0.9813         80        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1297/1297 [06:19<00:00,  3.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:13<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.853      0.723      0.804       0.62\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 49, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11 epochs completed in 1.367 hours.\n",
      "Optimizer stripped from runs/train-ghost/yolov8-ghostp2-optimized3/weights/last.pt, 3.7MB\n",
      "Optimizer stripped from runs/train-ghost/yolov8-ghostp2-optimized3/weights/best.pt, 3.7MB\n",
      "\n",
      "Validating runs/train-ghost/yolov8-ghostp2-optimized3/weights/best.pt...\n",
      "Ultralytics 8.3.156 üöÄ Python-3.10.12 torch-2.7.1+cu126 CUDA:1 (NVIDIA H100 80GB HBM3 MIG 3g.40gb, 40320MiB)\n",
      "YOLOv8-ghost-p2 summary (fused): 179 layers, 1,601,308 parameters, 0 gradients, 8.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105/105 [01:19<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       6675      13693      0.847      0.728      0.806      0.621\n",
      "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/train-ghost/yolov8-ghostp2-optimized3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ffc0cff05e0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99877,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,\n",
       "            0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,\n",
       "            0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99794,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,\n",
       "            0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99766,     0.99713,     0.99713,     0.99668,     0.99668,     0.99668,     0.99668,     0.99668,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,\n",
       "             0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9963,      0.9961,      0.9961,      0.9961,\n",
       "             0.9961,      0.9961,      0.9961,      0.9961,      0.9961,      0.9961,      0.9961,     0.99568,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,     0.99567,\n",
       "            0.99567,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99495,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,\n",
       "            0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,\n",
       "            0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99472,     0.99455,     0.99455,     0.99455,     0.99455,     0.99455,\n",
       "            0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99445,     0.99413,     0.99413,     0.99413,     0.99413,     0.99413,     0.99413,     0.99413,     0.99413,     0.99413,     0.99413,     0.99413,     0.99391,     0.99388,     0.99388,\n",
       "            0.99388,     0.99388,     0.99388,     0.99388,     0.99388,     0.99388,     0.99388,     0.99388,     0.99388,      0.9935,      0.9935,      0.9935,      0.9935,      0.9935,     0.99342,     0.99342,     0.99342,     0.99342,     0.99342,     0.99342,     0.99342,     0.99342,     0.99335,\n",
       "            0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,     0.99335,      0.9932,      0.9932,      0.9932,     0.99299,     0.99292,\n",
       "            0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,     0.99292,\n",
       "            0.99292,     0.99292,     0.99292,     0.99292,     0.99277,     0.99277,     0.99259,     0.99254,     0.99254,     0.99254,     0.99254,     0.99254,     0.99254,     0.99254,     0.99254,     0.99216,     0.99204,     0.99204,     0.99204,     0.99193,     0.99193,     0.99193,     0.99193,\n",
       "            0.99178,     0.99178,     0.99161,     0.99145,     0.99145,      0.9913,      0.9913,      0.9913,      0.9913,      0.9913,      0.9913,      0.9913,      0.9913,      0.9913,      0.9913,     0.99116,     0.99116,       0.991,      0.9907,      0.9907,      0.9907,     0.99064,     0.99064,\n",
       "            0.99064,     0.99064,     0.99064,     0.99053,     0.99053,     0.99053,     0.99042,     0.99042,     0.99042,     0.99027,     0.99015,     0.99015,     0.99015,        0.99,     0.98969,     0.98969,      0.9892,     0.98905,     0.98874,     0.98862,     0.98862,     0.98846,     0.98837,\n",
       "            0.98837,     0.98837,     0.98806,     0.98792,     0.98777,     0.98762,     0.98749,     0.98743,     0.98743,     0.98743,     0.98743,     0.98722,     0.98722,     0.98722,     0.98722,     0.98714,     0.98714,     0.98714,     0.98684,     0.98643,     0.98643,     0.98628,     0.98616,\n",
       "            0.98603,     0.98594,     0.98594,     0.98594,     0.98565,     0.98555,      0.9854,     0.98532,     0.98532,      0.9852,     0.98513,     0.98513,     0.98513,     0.98504,     0.98504,     0.98495,     0.98495,     0.98484,     0.98484,     0.98461,     0.98461,     0.98433,     0.98415,\n",
       "            0.98415,     0.98415,     0.98415,     0.98406,     0.98406,     0.98399,     0.98399,      0.9839,      0.9839,     0.98372,     0.98372,     0.98372,     0.98359,     0.98333,     0.98306,     0.98281,     0.98269,     0.98247,     0.98247,     0.98222,      0.9818,     0.98173,     0.98173,\n",
       "            0.98154,     0.98154,     0.98142,     0.98089,     0.98076,     0.98054,     0.98054,     0.98048,     0.98048,     0.97997,     0.97987,     0.97979,     0.97979,     0.97941,     0.97931,     0.97913,     0.97913,     0.97901,     0.97879,     0.97853,     0.97819,      0.9778,     0.97759,\n",
       "            0.97759,     0.97754,     0.97754,     0.97717,     0.97708,       0.977,     0.97665,     0.97656,     0.97637,     0.97637,     0.97626,     0.97593,     0.97583,     0.97547,     0.97526,     0.97437,       0.974,     0.97382,     0.97363,     0.97363,     0.97363,     0.97363,     0.97363,\n",
       "            0.97363,     0.97363,     0.97345,     0.97345,     0.97337,     0.97328,     0.97321,     0.97313,     0.97304,     0.97258,     0.97201,     0.97178,      0.9716,     0.97154,     0.97142,      0.9714,      0.9714,     0.97138,     0.97138,      0.9708,     0.97047,     0.96953,     0.96934,\n",
       "            0.96889,     0.96859,     0.96826,     0.96745,     0.96713,     0.96684,     0.96664,      0.9661,     0.96605,     0.96585,     0.96578,     0.96562,     0.96544,     0.96536,     0.96505,     0.96492,     0.96488,     0.96488,     0.96473,     0.96453,     0.96424,     0.96392,     0.96351,\n",
       "            0.96302,      0.9627,     0.96252,     0.96211,      0.9616,     0.96143,     0.96128,     0.96121,     0.96092,     0.96022,     0.96002,     0.95974,     0.95912,     0.95879,     0.95871,     0.95864,     0.95838,     0.95809,     0.95784,     0.95723,     0.95677,     0.95658,     0.95573,\n",
       "            0.95503,     0.95477,     0.95442,     0.95403,     0.95357,     0.95318,     0.95283,     0.95236,     0.95177,     0.95164,     0.95126,     0.95074,     0.95045,     0.95032,     0.94986,      0.9496,     0.94893,     0.94838,     0.94776,     0.94768,     0.94746,     0.94709,     0.94634,\n",
       "             0.9456,     0.94505,     0.94501,     0.94435,     0.94381,     0.94349,     0.94287,     0.94243,     0.94168,     0.94136,     0.94054,      0.9401,     0.93938,     0.93835,     0.93813,     0.93752,     0.93683,     0.93654,      0.9362,     0.93605,      0.9356,     0.93508,     0.93419,\n",
       "            0.93349,      0.9327,     0.93195,     0.93114,     0.93064,     0.92996,      0.9292,     0.92873,     0.92794,     0.92699,     0.92557,     0.92519,     0.92482,     0.92379,     0.92286,     0.92232,     0.92124,     0.92065,      0.9202,     0.91844,     0.91765,     0.91618,     0.91482,\n",
       "            0.91332,     0.91269,     0.91181,     0.91067,     0.90979,     0.90829,     0.90744,     0.90654,     0.90548,     0.90426,     0.90384,     0.90384,     0.90281,     0.90224,     0.90161,     0.90111,     0.90004,     0.89844,     0.89772,      0.8963,     0.89515,     0.89319,     0.89297,\n",
       "            0.89218,     0.89115,     0.89037,     0.88977,     0.88941,     0.88824,     0.88746,     0.88578,     0.88479,     0.88338,     0.88174,     0.88003,     0.87793,     0.87616,     0.87523,     0.87465,     0.87369,     0.87267,     0.87104,      0.8701,     0.86764,     0.86689,     0.86619,\n",
       "            0.86443,     0.86382,     0.86261,     0.86186,     0.86145,     0.86139,     0.86011,     0.85892,     0.85782,     0.85688,     0.85586,     0.85442,     0.85255,     0.85053,     0.84874,     0.84675,      0.8445,     0.84368,     0.84195,      0.8403,     0.83932,     0.83828,     0.83717,\n",
       "            0.83622,     0.83471,     0.83287,     0.83121,     0.82902,     0.82725,     0.82671,     0.82451,     0.82229,     0.82113,     0.81896,     0.81768,     0.81632,     0.81491,     0.81228,     0.81074,      0.8083,     0.80697,     0.80422,     0.80113,     0.79957,      0.7976,     0.79562,\n",
       "            0.79347,     0.79026,      0.7879,     0.78646,     0.78356,     0.78173,      0.7798,      0.7764,     0.77349,      0.7716,     0.76729,     0.76388,     0.76062,      0.7571,     0.75475,     0.75236,     0.74942,     0.74557,      0.7427,     0.73958,     0.73728,     0.73348,     0.73097,\n",
       "            0.72814,      0.7255,     0.72244,     0.71807,     0.71498,     0.71006,     0.70535,     0.69995,     0.69564,      0.6936,     0.69028,     0.68403,     0.67868,     0.67378,     0.66976,     0.66656,     0.66195,     0.65758,     0.65383,     0.65047,     0.64502,     0.63849,     0.63354,\n",
       "            0.62847,     0.62274,     0.61802,     0.61326,     0.61008,     0.60659,     0.60176,     0.59723,     0.59214,     0.58692,     0.58164,     0.57717,     0.57246,       0.565,     0.56021,     0.55476,     0.55008,     0.54676,     0.54043,     0.53028,      0.5207,     0.51555,     0.50571,\n",
       "            0.50281,     0.49346,      0.4887,     0.48306,     0.47795,     0.46857,     0.46379,     0.45951,     0.45303,     0.44839,     0.44049,     0.42999,     0.42235,     0.41745,     0.41086,     0.40577,     0.40064,     0.39331,     0.38914,     0.38476,     0.37732,     0.36998,     0.35969,\n",
       "            0.35409,     0.34648,     0.34039,     0.33059,     0.32446,      0.3196,     0.31439,     0.30868,     0.30268,     0.29832,     0.29118,     0.28663,     0.27938,      0.2674,     0.26218,     0.25487,     0.25006,     0.24062,     0.23396,     0.22579,     0.21871,      0.2146,     0.21138,\n",
       "             0.2032,     0.19734,     0.19386,     0.18931,     0.18262,     0.17719,     0.17212,     0.16744,     0.16421,     0.15807,     0.15289,     0.14969,     0.14624,     0.14053,     0.13749,     0.13361,     0.12982,     0.12509,     0.12147,     0.11687,     0.11493,     0.10958,     0.10676,\n",
       "            0.10158,    0.098594,    0.096706,    0.095107,    0.092217,    0.089295,    0.086131,    0.083996,    0.080593,     0.07858,    0.076944,    0.074506,    0.072424,     0.07032,    0.067567,    0.066069,    0.064286,    0.062653,    0.061306,    0.060373,    0.058632,    0.056838,    0.055991,\n",
       "           0.054589,    0.053259,    0.051824,    0.050812,    0.049826,    0.048851,    0.047538,    0.046592,    0.045945,    0.045298,    0.044651,    0.044004,    0.043357,     0.04271,    0.042062,    0.041415,    0.040768,    0.040121,    0.039474,    0.038827,     0.03818,    0.037533,    0.036886,\n",
       "           0.036238,    0.035591,    0.034944,    0.034297,     0.03365,    0.033003,    0.032356,    0.031709,    0.031062,    0.030414,    0.029767,     0.02912,    0.028473,    0.027826,    0.027179,    0.026532,    0.025885,    0.025237,     0.02459,    0.023943,    0.023296,    0.022649,    0.022002,\n",
       "           0.021355,    0.020708,    0.020061,    0.019413,    0.018766,    0.018119,    0.017472,    0.016825,    0.016178,    0.015531,    0.014884,    0.014237,    0.013589,    0.012942,    0.012295,    0.011648,    0.011001,    0.010354,   0.0097067,   0.0090596,   0.0084125,   0.0077654,   0.0071183,\n",
       "          0.0064711,    0.005824,   0.0051769,   0.0045298,   0.0038827,   0.0032356,   0.0025885,   0.0019413,   0.0012942,  0.00064711,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.089762,    0.089762,     0.13169,     0.16384,     0.19011,     0.21385,     0.23474,     0.25257,     0.26947,     0.28419,     0.29865,     0.31145,     0.32353,     0.33442,      0.3456,     0.35601,     0.36533,      0.3743,     0.38345,     0.39173,     0.39989,      0.4072,     0.41472,\n",
       "            0.42208,     0.42904,     0.43513,     0.44149,      0.4473,     0.45301,     0.45837,     0.46343,     0.46876,     0.47325,     0.47807,     0.48318,     0.48774,     0.49184,     0.49618,     0.50066,     0.50425,      0.5082,     0.51205,      0.5159,     0.51952,     0.52329,     0.52642,\n",
       "            0.52964,     0.53252,     0.53579,      0.5391,     0.54196,     0.54438,     0.54796,     0.55069,     0.55329,      0.5561,     0.55874,     0.56091,      0.5637,     0.56662,     0.56896,     0.57197,      0.5746,      0.5772,     0.57946,     0.58185,     0.58369,     0.58573,     0.58819,\n",
       "            0.59053,     0.59269,     0.59477,     0.59612,     0.59801,     0.59996,     0.60231,      0.6044,     0.60672,     0.60872,     0.61055,     0.61251,      0.6143,     0.61572,     0.61794,     0.61929,     0.62126,     0.62293,     0.62456,     0.62595,     0.62753,     0.62938,     0.63116,\n",
       "            0.63259,      0.6342,     0.63589,     0.63741,     0.63868,     0.64019,     0.64158,     0.64296,     0.64432,     0.64608,       0.648,      0.6496,     0.65048,     0.65192,     0.65295,     0.65465,      0.6554,     0.65694,     0.65807,     0.65905,     0.66037,     0.66119,     0.66237,\n",
       "            0.66318,      0.6648,     0.66559,     0.66699,     0.66779,     0.66906,     0.67011,      0.6711,     0.67243,     0.67338,     0.67499,     0.67576,     0.67667,     0.67781,     0.67864,     0.67958,     0.68029,     0.68149,     0.68235,     0.68339,     0.68411,     0.68556,     0.68655,\n",
       "            0.68748,       0.688,     0.68888,      0.6896,     0.69043,     0.69127,     0.69221,     0.69379,     0.69487,     0.69562,     0.69652,     0.69706,     0.69769,     0.69856,      0.6995,     0.70027,     0.70116,     0.70201,     0.70289,       0.704,     0.70407,     0.70494,      0.7058,\n",
       "            0.70627,     0.70703,     0.70805,     0.70902,      0.7098,     0.71081,     0.71153,     0.71256,     0.71352,      0.7144,     0.71514,     0.71602,     0.71627,     0.71703,     0.71798,     0.71843,     0.71904,     0.71953,     0.72056,     0.72126,     0.72151,     0.72211,     0.72286,\n",
       "            0.72357,      0.7245,      0.7252,     0.72595,     0.72614,     0.72674,     0.72731,     0.72775,     0.72854,     0.72913,     0.72929,      0.7299,     0.73065,     0.73131,     0.73209,     0.73207,     0.73298,     0.73373,     0.73452,     0.73512,     0.73531,      0.7363,      0.7369,\n",
       "            0.73786,     0.73844,     0.73837,     0.73893,     0.73943,     0.74016,      0.7401,     0.74056,     0.74091,     0.74191,     0.74198,     0.74264,     0.74337,     0.74415,     0.74418,     0.74472,     0.74508,     0.74578,     0.74598,     0.74693,     0.74748,     0.74846,     0.74869,\n",
       "            0.74916,     0.74959,     0.74958,     0.75017,     0.75064,     0.75138,     0.75147,     0.75234,     0.75283,     0.75289,     0.75335,     0.75394,     0.75423,     0.75424,     0.75471,     0.75508,     0.75519,     0.75565,     0.75611,      0.7562,     0.75668,     0.75711,     0.75722,\n",
       "             0.7579,     0.75817,     0.75829,     0.75856,     0.75918,     0.75933,     0.75973,     0.75996,     0.76058,     0.76073,     0.76133,     0.76143,     0.76188,     0.76222,      0.7623,     0.76276,     0.76318,     0.76331,     0.76385,     0.76414,     0.76425,     0.76465,     0.76491,\n",
       "            0.76497,     0.76522,     0.76532,     0.76586,     0.76643,     0.76648,      0.7671,     0.76738,     0.76746,     0.76801,     0.76842,     0.76853,       0.769,     0.76906,     0.76993,     0.77021,     0.77021,      0.7705,     0.77096,     0.77106,      0.7714,     0.77145,     0.77183,\n",
       "            0.77241,     0.77267,     0.77295,     0.77302,     0.77304,      0.7735,     0.77365,     0.77404,     0.77409,     0.77434,      0.7745,     0.77458,     0.77484,     0.77504,     0.77511,     0.77544,     0.77541,     0.77565,     0.77575,     0.77621,     0.77666,      0.7767,     0.77667,\n",
       "            0.77671,     0.77729,     0.77742,     0.77737,     0.77756,     0.77759,     0.77789,     0.77774,     0.77811,     0.77849,     0.77858,     0.77874,     0.77872,     0.77914,     0.77912,     0.77945,      0.7796,     0.77953,      0.7798,     0.77976,     0.78012,     0.78036,     0.78029,\n",
       "            0.78071,     0.78069,     0.78088,     0.78097,     0.78112,     0.78103,     0.78093,     0.78114,     0.78118,     0.78121,      0.7813,     0.78148,     0.78158,     0.78164,     0.78148,     0.78171,     0.78184,     0.78198,     0.78229,     0.78252,     0.78239,     0.78231,     0.78214,\n",
       "            0.78219,     0.78248,      0.7827,     0.78274,     0.78273,     0.78285,     0.78298,     0.78305,     0.78322,     0.78327,     0.78314,     0.78323,     0.78327,     0.78323,     0.78319,     0.78332,     0.78309,     0.78311,     0.78306,      0.7831,     0.78302,     0.78287,     0.78272,\n",
       "            0.78294,      0.7831,     0.78296,     0.78291,      0.7828,     0.78309,     0.78315,     0.78326,     0.78328,     0.78365,     0.78356,     0.78372,      0.7837,     0.78387,     0.78394,     0.78404,     0.78419,     0.78428,     0.78426,     0.78418,     0.78412,     0.78408,     0.78412,\n",
       "            0.78405,     0.78386,     0.78382,     0.78368,     0.78368,     0.78361,     0.78369,     0.78372,     0.78349,     0.78289,      0.7824,     0.78235,     0.78234,     0.78222,     0.78219,     0.78217,     0.78178,       0.782,     0.78193,     0.78199,      0.7818,     0.78182,     0.78161,\n",
       "            0.78142,     0.78183,     0.78176,      0.7818,      0.7817,     0.78172,     0.78152,     0.78153,     0.78159,     0.78157,     0.78138,     0.78116,      0.7812,     0.78082,     0.78055,     0.78047,      0.7806,     0.78054,     0.78064,     0.78065,     0.78081,     0.78078,     0.78083,\n",
       "            0.78092,     0.78095,     0.78095,     0.78081,     0.78074,     0.78078,     0.78073,     0.78057,     0.78056,     0.78067,     0.78059,     0.78039,     0.78025,     0.78011,     0.77986,     0.77943,     0.77934,     0.77896,     0.77893,     0.77883,     0.77847,     0.77847,     0.77825,\n",
       "            0.77797,     0.77779,      0.7777,     0.77791,     0.77773,     0.77761,     0.77751,     0.77769,     0.77735,     0.77702,     0.77697,       0.777,     0.77685,     0.77686,     0.77659,     0.77653,     0.77636,     0.77592,     0.77575,     0.77545,     0.77529,     0.77499,     0.77468,\n",
       "            0.77414,     0.77407,     0.77417,     0.77407,     0.77384,     0.77363,     0.77337,     0.77323,     0.77306,     0.77288,     0.77297,     0.77288,     0.77284,     0.77257,      0.7724,     0.77217,     0.77206,     0.77187,     0.77177,     0.77144,     0.77146,     0.77118,     0.77126,\n",
       "            0.77081,     0.77088,     0.77087,     0.77069,     0.77056,     0.77036,     0.77052,     0.77027,     0.76993,     0.76978,     0.76933,     0.76918,     0.76913,     0.76896,      0.7685,     0.76834,       0.768,     0.76765,     0.76709,     0.76694,     0.76679,     0.76671,     0.76658,\n",
       "            0.76637,     0.76616,     0.76606,     0.76553,     0.76538,       0.765,     0.76451,     0.76416,     0.76402,     0.76389,      0.7631,     0.76312,     0.76294,     0.76266,     0.76241,     0.76228,     0.76204,     0.76202,     0.76148,     0.76143,     0.76097,     0.76086,     0.76011,\n",
       "            0.75991,     0.75936,     0.75905,     0.75887,     0.75866,     0.75822,     0.75781,     0.75778,     0.75721,     0.75707,     0.75671,     0.75656,     0.75626,     0.75588,     0.75537,     0.75534,     0.75473,     0.75465,     0.75425,     0.75415,     0.75355,     0.75296,      0.7525,\n",
       "            0.75189,      0.7517,     0.75144,     0.75124,     0.75034,     0.75031,     0.74988,     0.74977,     0.74914,     0.74832,      0.7481,     0.74759,     0.74725,     0.74679,     0.74675,     0.74607,     0.74581,     0.74552,     0.74519,     0.74476,     0.74448,     0.74389,     0.74307,\n",
       "            0.74279,     0.74226,     0.74204,     0.74129,     0.74097,      0.7406,     0.74043,     0.73991,     0.73975,     0.73907,     0.73878,      0.7377,     0.73692,      0.7367,     0.73595,     0.73593,     0.73522,     0.73514,     0.73458,     0.73326,     0.73311,     0.73213,     0.73204,\n",
       "             0.7312,     0.73057,     0.72983,     0.72937,     0.72887,     0.72809,     0.72766,     0.72712,     0.72678,     0.72637,     0.72605,     0.72505,     0.72473,     0.72381,     0.72293,     0.72262,     0.72206,     0.72198,     0.72095,     0.72059,     0.72025,     0.71966,     0.71955,\n",
       "            0.71896,     0.71879,       0.718,     0.71645,      0.7161,     0.71507,     0.71428,     0.71351,     0.71295,     0.71192,     0.71071,     0.71041,     0.70937,      0.7081,     0.70745,     0.70661,     0.70643,     0.70584,     0.70566,     0.70531,     0.70448,     0.70433,     0.70376,\n",
       "            0.70341,     0.70243,     0.70198,     0.70141,     0.70067,     0.70052,     0.69945,     0.69884,      0.6972,     0.69628,     0.69506,     0.69469,     0.69426,     0.69381,     0.69323,     0.69216,     0.69176,     0.69092,     0.69034,     0.68892,     0.68762,     0.68744,     0.68667,\n",
       "             0.6861,     0.68492,     0.68342,     0.68302,     0.68201,      0.6817,      0.6802,     0.67948,     0.67832,     0.67787,     0.67728,     0.67668,     0.67511,     0.67398,     0.67351,     0.67202,     0.67119,     0.67057,     0.66969,     0.66777,     0.66736,     0.66631,     0.66597,\n",
       "            0.66433,     0.66397,     0.66371,     0.66164,     0.66057,     0.65991,     0.65881,     0.65842,     0.65763,     0.65661,     0.65613,     0.65429,     0.65303,     0.65258,     0.65123,     0.65018,     0.64951,     0.64776,     0.64697,      0.6459,       0.644,     0.64336,     0.64165,\n",
       "            0.64034,     0.63916,     0.63825,     0.63595,     0.63524,     0.63358,     0.63259,     0.63195,     0.63025,     0.62924,     0.62748,     0.62651,     0.62552,     0.62332,     0.62243,     0.62035,     0.61911,     0.61813,     0.61559,     0.61409,     0.61167,      0.6098,     0.60921,\n",
       "            0.60782,     0.60606,     0.60356,     0.60233,      0.6003,     0.59921,     0.59719,     0.59588,     0.59384,     0.59256,     0.58972,      0.5888,     0.58599,     0.58543,     0.58284,     0.58067,     0.57993,     0.57763,     0.57561,     0.57349,     0.57215,     0.56915,     0.56808,\n",
       "            0.56582,     0.56338,     0.56239,      0.5593,     0.55764,     0.55544,     0.55275,     0.55122,     0.54801,     0.54511,     0.54384,     0.54057,     0.53778,      0.5359,     0.53293,     0.52874,     0.52713,     0.52349,     0.51985,      0.5184,     0.51469,      0.5105,     0.50605,\n",
       "            0.50304,     0.49919,     0.49475,     0.48969,      0.4877,      0.4844,     0.48023,     0.47561,      0.4711,     0.46663,      0.4641,     0.45823,     0.45234,     0.44675,     0.44256,     0.43777,     0.43241,      0.4268,      0.4238,      0.4188,     0.41271,     0.40746,     0.40163,\n",
       "            0.39538,     0.38802,     0.38193,     0.37533,     0.36904,     0.36173,     0.35504,     0.34979,       0.342,     0.32994,     0.32309,     0.31711,     0.31178,      0.3054,     0.29993,     0.29368,     0.28751,     0.28065,     0.27436,     0.26849,     0.26123,     0.24923,     0.24327,\n",
       "            0.23797,     0.23024,      0.2244,     0.21783,     0.21119,     0.19491,     0.18487,     0.16443,     0.15341,     0.14503,     0.13707,      0.1297,     0.11543,     0.11034,     0.10327,    0.096139,     0.08509,    0.079308,    0.074169,    0.065046,    0.061066,    0.056656,    0.048618,\n",
       "           0.042474,    0.038681,    0.033463,    0.027081,     0.02402,    0.019505,     0.01706,    0.013042,    0.012296,    0.011423,   0.0085233,   0.0074616,   0.0063341,   0.0056009,   0.0048672,   0.0042783,   0.0039801,   0.0036818,    0.002801,   0.0022726,   0.0020579,   0.0019009,   0.0010951,\n",
       "         0.00072667,  0.00058056,  0.00050575,  0.00040944,  0.00026608,  0.00022332,  0.00018055,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.047164,    0.047164,     0.07098,    0.090094,     0.10632,     0.12147,     0.13521,     0.14726,     0.15897,     0.16941,     0.17985,     0.18931,     0.19841,     0.20674,     0.21546,     0.22372,     0.23119,      0.2385,     0.24607,     0.25301,     0.25992,     0.26627,      0.2728,\n",
       "            0.27926,     0.28547,     0.29102,     0.29681,     0.30227,     0.30763,     0.31269,     0.31757,     0.32269,     0.32716,     0.33187,     0.33687,     0.34139,     0.34554,     0.34997,     0.35451,     0.35822,     0.36234,     0.36634,     0.37039,     0.37429,     0.37825,     0.38164,\n",
       "            0.38513,     0.38832,     0.39202,     0.39567,     0.39888,     0.40168,      0.4057,     0.40886,     0.41188,      0.4151,     0.41813,     0.42079,     0.42401,     0.42743,     0.43022,     0.43379,     0.43688,     0.43995,     0.44267,     0.44552,     0.44781,     0.45039,     0.45354,\n",
       "            0.45642,     0.45909,     0.46172,     0.46351,     0.46602,     0.46856,      0.4715,     0.47411,      0.4771,     0.47981,     0.48221,     0.48482,     0.48718,      0.4891,     0.49209,     0.49401,     0.49663,     0.49884,     0.50099,     0.50289,     0.50507,     0.50777,      0.5102,\n",
       "            0.51222,     0.51435,     0.51672,     0.51883,     0.52063,     0.52275,     0.52467,     0.52658,     0.52861,     0.53105,     0.53371,     0.53589,     0.53711,     0.53921,     0.54084,      0.5433,     0.54442,     0.54671,     0.54855,      0.5501,     0.55205,     0.55346,     0.55525,\n",
       "            0.55655,     0.55904,     0.56018,     0.56235,      0.5636,     0.56565,     0.56725,     0.56875,     0.57082,     0.57228,     0.57483,     0.57623,      0.5777,     0.57959,     0.58092,     0.58244,      0.5836,     0.58556,     0.58691,     0.58867,     0.58989,     0.59224,      0.5938,\n",
       "            0.59531,     0.59637,     0.59786,     0.59918,     0.60059,     0.60195,     0.60357,     0.60626,     0.60816,     0.60948,     0.61112,     0.61225,     0.61341,     0.61498,     0.61656,     0.61801,     0.61954,     0.62116,     0.62272,      0.6246,     0.62479,     0.62629,     0.62781,\n",
       "            0.62879,     0.63009,     0.63189,     0.63371,     0.63518,     0.63699,     0.63824,     0.64018,     0.64187,     0.64334,     0.64473,     0.64645,     0.64689,     0.64824,     0.64988,     0.65101,     0.65206,      0.6531,     0.65515,     0.65664,     0.65712,     0.65835,     0.65981,\n",
       "            0.66125,     0.66294,     0.66427,     0.66584,     0.66615,     0.66748,     0.66874,     0.66974,     0.67121,      0.6726,     0.67293,     0.67423,     0.67566,     0.67685,     0.67824,     0.67841,     0.68014,      0.6816,     0.68318,     0.68454,     0.68493,     0.68665,      0.6878,\n",
       "            0.68981,      0.6911,     0.69115,     0.69247,     0.69361,      0.6953,      0.6953,     0.69647,     0.69736,     0.69937,     0.69959,     0.70095,     0.70249,     0.70406,     0.70423,     0.70549,     0.70618,     0.70781,     0.70822,     0.71006,     0.71128,     0.71312,     0.71354,\n",
       "            0.71493,     0.71589,     0.71605,     0.71745,     0.71873,     0.72039,     0.72072,     0.72247,     0.72363,     0.72386,     0.72508,      0.7263,     0.72735,     0.72758,     0.72869,     0.72982,     0.73015,     0.73132,     0.73259,     0.73288,      0.7343,     0.73536,     0.73558,\n",
       "            0.73718,     0.73814,     0.73845,     0.73936,     0.74086,     0.74122,     0.74225,     0.74321,     0.74487,     0.74522,     0.74651,     0.74678,     0.74797,     0.74904,     0.74925,     0.75063,     0.75168,     0.75203,     0.75365,     0.75478,     0.75511,     0.75618,     0.75733,\n",
       "            0.75751,     0.75836,     0.75853,     0.76003,      0.7615,     0.76167,     0.76297,     0.76403,     0.76434,      0.7655,     0.76689,     0.76728,     0.76849,     0.76875,     0.77086,     0.77186,     0.77202,     0.77296,      0.7744,     0.77468,     0.77589,     0.77606,     0.77729,\n",
       "            0.77898,     0.77952,     0.78084,       0.781,     0.78203,     0.78354,     0.78393,     0.78508,     0.78525,     0.78663,     0.78743,     0.78779,      0.7889,     0.78964,     0.78986,     0.79094,     0.79104,     0.79193,     0.79223,     0.79365,     0.79483,       0.795,     0.79582,\n",
       "              0.796,     0.79738,     0.79846,      0.7985,     0.79941,     0.79963,     0.80099,     0.80101,     0.80228,     0.80342,     0.80377,     0.80465,     0.80464,     0.80605,      0.8061,      0.8074,     0.80824,     0.80827,     0.80941,     0.80957,     0.81068,     0.81206,     0.81226,\n",
       "            0.81334,     0.81345,     0.81457,     0.81494,     0.81566,     0.81652,     0.81666,      0.8174,     0.81782,     0.81867,     0.81888,     0.81979,      0.8201,     0.82121,     0.82139,     0.82278,     0.82369,      0.8242,     0.82534,     0.82594,     0.82679,     0.82688,     0.82753,\n",
       "            0.82772,     0.82892,     0.83024,     0.83061,     0.83132,      0.8316,     0.83272,     0.83316,     0.83393,     0.83432,     0.83494,     0.83515,     0.83656,     0.83715,     0.83744,     0.83821,     0.83827,     0.83904,     0.83918,     0.84016,     0.84026,     0.84104,     0.84218,\n",
       "            0.84268,     0.84354,     0.84381,     0.84437,     0.84446,     0.84576,      0.8459,     0.84695,     0.84725,     0.84867,     0.84873,     0.84972,     0.84997,     0.85118,     0.85153,     0.85259,     0.85395,     0.85417,     0.85502,     0.85538,     0.85615,     0.85627,     0.85688,\n",
       "            0.85712,     0.85745,     0.85753,     0.85867,     0.85896,     0.85986,     0.86036,     0.86118,     0.86133,     0.86179,     0.86229,     0.86261,     0.86302,     0.86334,     0.86402,     0.86421,      0.8644,     0.86494,     0.86561,     0.86582,     0.86649,     0.86681,     0.86718,\n",
       "            0.86748,     0.86917,     0.86923,     0.86996,     0.87014,     0.87098,     0.87102,     0.87216,     0.87266,     0.87359,     0.87369,     0.87436,     0.87458,     0.87522,     0.87566,     0.87578,     0.87712,     0.87755,      0.8791,     0.87921,     0.88024,     0.88038,     0.88117,\n",
       "            0.88167,     0.88279,     0.88316,     0.88395,     0.88405,     0.88507,     0.88533,     0.88592,     0.88615,     0.88706,      0.8872,     0.88808,     0.88834,      0.8894,     0.88958,     0.89017,     0.89016,     0.89054,     0.89054,     0.89137,     0.89238,     0.89261,     0.89289,\n",
       "             0.8929,     0.89389,     0.89403,     0.89509,     0.89546,     0.89629,     0.89637,      0.8976,     0.89769,     0.89872,     0.89882,     0.90003,     0.90005,     0.90106,     0.90113,     0.90161,     0.90162,     0.90235,      0.9024,       0.903,     0.90317,     0.90377,     0.90377,\n",
       "            0.90419,     0.90426,     0.90518,     0.90533,     0.90643,      0.9065,     0.90685,     0.90699,     0.90756,     0.90761,      0.9088,     0.90895,     0.90979,     0.90983,     0.91124,     0.91197,      0.9122,     0.91277,     0.91302,      0.9139,     0.91435,     0.91534,     0.91559,\n",
       "            0.91624,     0.91675,     0.91764,      0.9177,     0.91836,     0.91844,      0.9202,     0.92033,     0.92063,     0.92079,     0.92156,     0.92176,      0.9227,     0.92271,     0.92327,     0.92357,      0.9246,     0.92485,      0.9254,     0.92556,     0.92634,     0.92635,     0.92761,\n",
       "            0.92758,     0.92845,     0.92845,     0.92912,     0.92927,     0.92987,     0.93059,     0.93069,     0.93156,     0.93186,     0.93247,     0.93266,      0.9332,     0.93339,     0.93402,      0.9341,      0.9348,     0.93489,     0.93523,     0.93541,     0.93602,     0.93601,     0.93611,\n",
       "            0.93627,     0.93649,     0.93664,     0.93719,     0.93736,      0.9376,     0.93794,     0.93799,     0.93831,     0.93862,     0.93946,     0.93964,     0.94048,     0.94044,     0.94134,     0.94136,     0.94158,     0.94167,     0.94222,     0.94259,     0.94284,     0.94357,     0.94362,\n",
       "             0.9443,     0.94443,     0.94485,     0.94498,     0.94519,     0.94559,     0.94625,     0.94624,     0.94685,     0.94751,     0.94749,     0.94774,     0.94771,      0.9479,     0.94817,     0.94893,     0.94931,      0.9496,     0.94967,     0.95004,     0.95001,     0.95037,     0.95071,\n",
       "            0.95068,     0.95126,     0.95144,     0.95169,     0.95176,     0.95236,     0.95234,     0.95261,     0.95281,     0.95328,     0.95344,     0.95411,     0.95447,      0.9546,     0.95485,     0.95524,     0.95572,     0.95604,     0.95675,     0.95718,     0.95783,     0.95808,     0.95817,\n",
       "            0.95843,      0.9586,     0.95876,     0.95872,     0.95898,     0.95984,     0.95992,     0.96021,     0.96018,     0.96082,     0.96091,     0.96117,     0.96126,     0.96141,     0.96202,     0.96205,     0.96218,     0.96252,     0.96301,     0.96299,     0.96319,     0.96351,      0.9636,\n",
       "            0.96402,     0.96423,     0.96452,     0.96488,     0.96485,     0.96489,     0.96483,     0.96525,     0.96532,      0.9656,     0.96575,     0.96573,     0.96601,     0.96664,     0.96684,     0.96702,     0.96725,     0.96733,     0.96755,     0.96801,     0.96857,     0.96868,     0.96894,\n",
       "             0.9691,      0.9695,     0.96985,     0.97069,     0.97119,     0.97126,     0.97131,     0.97128,      0.9713,     0.97149,     0.97154,     0.97153,       0.972,     0.97197,     0.97257,     0.97301,     0.97312,     0.97319,     0.97316,     0.97333,     0.97339,     0.97363,     0.97359,\n",
       "            0.97356,     0.97349,     0.97353,     0.97351,     0.97345,      0.9737,     0.97374,     0.97435,     0.97534,     0.97558,     0.97582,     0.97592,     0.97625,     0.97631,     0.97655,     0.97674,     0.97697,     0.97707,     0.97717,     0.97748,     0.97755,     0.97766,      0.9778,\n",
       "            0.97819,     0.97852,     0.97878,     0.97911,     0.97906,      0.9793,     0.97939,     0.97965,     0.97976,     0.97985,     0.97993,     0.98046,      0.9804,     0.98052,     0.98075,     0.98093,     0.98139,     0.98161,     0.98172,     0.98168,     0.98233,     0.98245,     0.98267,\n",
       "            0.98292,     0.98332,     0.98358,     0.98364,     0.98376,     0.98385,     0.98397,     0.98394,     0.98403,     0.98415,     0.98408,     0.98405,     0.98432,      0.9847,     0.98483,     0.98491,     0.98502,     0.98499,     0.98506,     0.98516,     0.98524,     0.98565,     0.98563,\n",
       "            0.98591,     0.98601,     0.98641,     0.98638,     0.98713,      0.9871,      0.9872,     0.98716,     0.98727,     0.98739,     0.98748,     0.98762,     0.98805,      0.9882,      0.9883,     0.98858,     0.98874,      0.9892,     0.98967,     0.99015,     0.99011,      0.9904,     0.99037,\n",
       "             0.9905,     0.99063,      0.9906,     0.99053,     0.99068,       0.991,     0.99112,     0.99128,     0.99121,     0.99114,     0.99111,     0.99143,     0.99175,     0.99191,     0.99185,     0.99216,     0.99253,     0.99246,     0.99259,     0.99277,      0.9929,     0.99282,     0.99274,\n",
       "             0.9929,     0.99282,     0.99274,     0.99264,     0.99282,     0.99298,     0.99313,     0.99327,     0.99319,     0.99334,     0.99329,     0.99318,     0.99331,     0.99345,     0.99388,     0.99379,      0.9937,     0.99412,     0.99407,     0.99398,     0.99442,     0.99433,     0.99452,\n",
       "             0.9947,     0.99458,     0.99447,     0.99466,     0.99455,     0.99442,     0.99429,     0.99418,     0.99402,     0.99486,     0.99473,     0.99461,     0.99567,     0.99557,     0.99547,     0.99536,     0.99567,     0.99599,     0.99589,     0.99625,     0.99613,     0.99591,      0.9958,\n",
       "            0.99623,     0.99664,     0.99712,     0.99762,     0.99753,      0.9973,     0.99785,     0.99756,     0.99737,     0.99721,     0.99703,      0.9979,     0.99762,     0.99875,     0.99866,     0.99856,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.92704,     0.92704,     0.91054,     0.90265,     0.89695,     0.89286,     0.88943,     0.88673,     0.88374,     0.88118,     0.87972,     0.87789,     0.87585,     0.87446,     0.87271,     0.87118,     0.87023,      0.8692,     0.86818,     0.86723,     0.86643,     0.86504,     0.86446,\n",
       "            0.86387,     0.86314,     0.86197,     0.86132,     0.85993,     0.85898,     0.85818,     0.85708,     0.85642,     0.85511,     0.85452,     0.85416,     0.85372,     0.85299,     0.85226,     0.85182,     0.85124,     0.85058,     0.85022,      0.8497,      0.8489,     0.84875,     0.84817,\n",
       "            0.84773,     0.84708,     0.84605,     0.84561,      0.8451,     0.84437,     0.84386,      0.8432,     0.84255,     0.84218,     0.84182,     0.84094,     0.84065,     0.84021,     0.83977,     0.83933,     0.83911,      0.8389,      0.8386,     0.83838,     0.83795,     0.83736,     0.83656,\n",
       "            0.83627,     0.83597,     0.83554,     0.83503,     0.83429,     0.83378,     0.83356,     0.83342,     0.83305,     0.83232,     0.83196,     0.83152,     0.83115,     0.83079,     0.83028,     0.82969,      0.8294,     0.82918,     0.82904,     0.82874,     0.82838,     0.82758,     0.82728,\n",
       "            0.82692,     0.82689,     0.82648,     0.82626,     0.82597,     0.82568,     0.82553,     0.82539,     0.82487,     0.82473,     0.82458,     0.82458,     0.82451,     0.82422,     0.82371,     0.82341,     0.82319,     0.82283,     0.82224,     0.82181,     0.82159,       0.821,     0.82071,\n",
       "            0.82035,     0.81991,     0.81985,     0.81947,     0.81925,     0.81874,     0.81852,     0.81837,     0.81805,     0.81786,     0.81742,     0.81684,     0.81655,     0.81611,     0.81589,      0.8156,     0.81538,     0.81501,     0.81484,     0.81443,     0.81414,     0.81377,     0.81362,\n",
       "            0.81341,      0.8129,      0.8126,     0.81217,     0.81187,     0.81173,     0.81136,     0.81085,     0.81041,     0.81012,     0.80967,     0.80914,     0.80881,     0.80844,     0.80822,     0.80778,     0.80757,     0.80705,     0.80676,     0.80654,      0.8064,     0.80618,      0.8059,\n",
       "            0.80552,     0.80538,     0.80508,     0.80464,     0.80428,     0.80399,     0.80385,      0.8034,     0.80318,     0.80311,     0.80282,     0.80238,     0.80233,     0.80216,     0.80202,     0.80143,     0.80136,     0.80102,     0.80048,     0.79997,      0.7999,     0.79953,     0.79924,\n",
       "            0.79888,     0.79866,     0.79844,       0.798,       0.798,     0.79756,     0.79712,     0.79677,     0.79658,     0.79603,     0.79595,     0.79559,     0.79537,      0.7953,     0.79522,     0.79495,     0.79471,     0.79449,      0.7942,     0.79376,     0.79369,     0.79369,     0.79354,\n",
       "            0.79311,     0.79274,     0.79252,     0.79208,     0.79174,     0.79121,     0.79108,      0.7906,     0.79026,     0.78997,     0.78983,      0.7896,     0.78931,     0.78909,     0.78894,     0.78858,     0.78851,     0.78807,     0.78799,     0.78783,     0.78756,     0.78748,     0.78748,\n",
       "            0.78683,     0.78661,     0.78639,     0.78602,     0.78551,     0.78515,     0.78496,     0.78478,     0.78449,     0.78434,      0.7839,     0.78376,     0.78317,     0.78292,     0.78266,     0.78215,     0.78201,     0.78164,      0.7812,     0.78106,     0.78047,     0.78018,     0.78018,\n",
       "            0.77981,      0.7793,     0.77923,     0.77879,     0.77843,     0.77835,     0.77806,     0.77748,     0.77697,     0.77689,     0.77675,     0.77667,     0.77631,     0.77587,      0.7758,     0.77529,     0.77504,     0.77495,     0.77434,     0.77372,     0.77361,     0.77331,     0.77264,\n",
       "            0.77258,     0.77222,     0.77222,     0.77178,     0.77142,     0.77136,     0.77127,     0.77076,     0.77061,     0.77054,     0.76996,     0.76978,     0.76952,     0.76937,     0.76901,     0.76857,     0.76842,     0.76806,     0.76755,     0.76747,     0.76696,     0.76689,     0.76645,\n",
       "            0.76594,     0.76594,     0.76523,     0.76521,     0.76426,     0.76372,     0.76364,     0.76331,     0.76324,     0.76243,       0.762,     0.76181,     0.76126,     0.76097,      0.7609,     0.76053,     0.76039,     0.76002,     0.75995,     0.75951,     0.75929,     0.75922,     0.75842,\n",
       "            0.75834,      0.7582,     0.75746,     0.75732,     0.75688,     0.75674,     0.75608,     0.75579,     0.75535,     0.75506,     0.75491,     0.75445,     0.75441,     0.75396,     0.75389,     0.75338,     0.75292,     0.75276,     0.75228,     0.75206,     0.75178,     0.75103,     0.75074,\n",
       "             0.7506,     0.75046,     0.74987,     0.74973,     0.74938,     0.74848,     0.74819,     0.74797,     0.74768,     0.74702,     0.74702,     0.74659,     0.74651,     0.74571,     0.74527,     0.74454,     0.74403,     0.74388,     0.74352,     0.74345,     0.74252,      0.7423,     0.74147,\n",
       "             0.7414,     0.74096,     0.74031,     0.74009,      0.7395,      0.7395,     0.73884,     0.73863,     0.73833,     0.73811,     0.73738,     0.73738,     0.73636,     0.73583,     0.73554,     0.73517,     0.73473,     0.73417,     0.73398,     0.73329,     0.73308,     0.73222,      0.7311,\n",
       "             0.7311,     0.73074,     0.73029,     0.72979,     0.72954,     0.72906,     0.72906,     0.72847,     0.72829,     0.72789,     0.72769,     0.72723,     0.72701,     0.72643,     0.72629,      0.7257,     0.72497,     0.72497,     0.72431,     0.72393,     0.72327,     0.72312,     0.72275,\n",
       "            0.72245,      0.7219,     0.72178,     0.72073,     0.72054,     0.71978,     0.71956,     0.71905,     0.71856,     0.71722,     0.71606,     0.71576,     0.71546,     0.71504,     0.71453,     0.71436,     0.71358,     0.71358,     0.71299,     0.71297,     0.71219,     0.71201,     0.71141,\n",
       "             0.7109,     0.71044,     0.71029,     0.70987,     0.70958,     0.70905,      0.7087,     0.70796,     0.70773,     0.70708,     0.70671,     0.70591,     0.70584,     0.70481,     0.70408,     0.70386,     0.70321,     0.70284,     0.70201,     0.70196,     0.70157,     0.70142,     0.70102,\n",
       "            0.70083,     0.70017,     0.69995,     0.69922,     0.69904,     0.69849,     0.69824,     0.69761,     0.69746,     0.69707,     0.69685,     0.69599,     0.69561,     0.69475,     0.69423,      0.6932,     0.69306,     0.69222,     0.69218,     0.69152,     0.69035,      0.6902,      0.6897,\n",
       "            0.68925,     0.68838,     0.68816,     0.68786,     0.68736,     0.68669,     0.68648,     0.68604,     0.68546,     0.68434,     0.68422,     0.68356,     0.68331,     0.68276,     0.68229,     0.68192,     0.68166,     0.68057,     0.68027,     0.67947,     0.67914,     0.67833,     0.67786,\n",
       "            0.67679,     0.67665,     0.67628,     0.67606,     0.67509,     0.67474,     0.67414,     0.67385,     0.67327,     0.67298,     0.67246,     0.67224,     0.67173,     0.67129,     0.67027,     0.66954,     0.66924,     0.66866,     0.66837,     0.66741,      0.6672,     0.66625,     0.66624,\n",
       "            0.66523,     0.66507,     0.66457,     0.66428,     0.66375,      0.6634,     0.66272,     0.66228,     0.66162,     0.66133,     0.66026,     0.65993,     0.65939,     0.65913,     0.65818,     0.65778,     0.65676,     0.65613,     0.65503,     0.65473,     0.65413,       0.654,      0.6532,\n",
       "             0.6529,     0.65216,     0.65202,     0.65092,     0.65062,     0.64979,     0.64873,     0.64818,     0.64756,     0.64723,      0.6458,     0.64573,     0.64522,     0.64474,     0.64408,     0.64386,     0.64318,      0.6431,     0.64217,     0.64202,     0.64107,     0.64092,     0.63983,\n",
       "            0.63946,     0.63858,     0.63807,     0.63755,     0.63719,     0.63646,     0.63572,     0.63565,      0.6347,     0.63437,     0.63349,     0.63319,     0.63239,     0.63188,     0.63076,      0.6307,     0.62975,     0.62961,      0.6288,      0.6285,     0.62755,     0.62642,     0.62576,\n",
       "            0.62463,      0.6243,     0.62375,     0.62342,      0.6221,     0.62188,       0.621,     0.62085,     0.61973,     0.61833,     0.61804,     0.61723,     0.61679,     0.61608,     0.61591,     0.61467,     0.61416,     0.61364,     0.61317,     0.61243,     0.61207,     0.61112,     0.60987,\n",
       "            0.60951,     0.60855,     0.60819,     0.60708,     0.60661,     0.60588,     0.60566,     0.60486,     0.60456,     0.60346,     0.60301,     0.60131,     0.60014,      0.5998,      0.5987,     0.59852,     0.59739,     0.59717,     0.59614,     0.59425,      0.5938,     0.59242,     0.59226,\n",
       "            0.59106,     0.59018,     0.58916,     0.58857,     0.58782,     0.58649,      0.5859,      0.5851,     0.58466,      0.5839,     0.58345,     0.58206,     0.58162,     0.58037,     0.57902,     0.57862,     0.57785,     0.57763,     0.57613,     0.57569,     0.57518,     0.57431,     0.57414,\n",
       "            0.57324,     0.57294,     0.57184,     0.56976,     0.56932,       0.568,     0.56703,     0.56592,     0.56519,      0.5638,     0.56223,     0.56186,     0.56047,     0.55868,      0.5578,      0.5567,      0.5564,     0.55564,     0.55535,     0.55476,     0.55355,     0.55333,     0.55255,\n",
       "            0.55205,     0.55072,     0.55006,     0.54909,     0.54802,     0.54781,     0.54649,     0.54576,     0.54375,     0.54258,     0.54108,     0.54064,     0.53997,     0.53943,     0.53855,     0.53713,     0.53661,     0.53557,     0.53489,     0.53314,     0.53157,     0.53127,     0.53037,\n",
       "             0.5297,     0.52831,     0.52652,     0.52605,     0.52487,     0.52443,     0.52264,     0.52162,     0.51997,     0.51938,     0.51862,     0.51788,     0.51596,     0.51462,     0.51401,     0.51222,     0.51119,     0.51044,      0.5094,      0.5071,     0.50661,     0.50537,     0.50494,\n",
       "            0.50296,     0.50245,     0.50208,     0.49964,     0.49843,     0.49762,     0.49634,     0.49583,     0.49492,     0.49373,     0.49317,     0.49097,     0.48956,     0.48903,     0.48746,     0.48623,     0.48537,     0.48336,     0.48246,     0.48128,     0.47902,     0.47828,     0.47634,\n",
       "            0.47484,     0.47345,     0.47239,     0.46987,     0.46906,     0.46724,     0.46613,     0.46544,     0.46358,     0.46247,     0.46058,     0.45954,     0.45842,     0.45598,       0.455,     0.45276,     0.45141,     0.45038,     0.44768,     0.44607,     0.44351,     0.44146,     0.44084,\n",
       "            0.43934,     0.43748,      0.4348,     0.43353,     0.43129,     0.43017,     0.42807,     0.42673,     0.42463,      0.4233,     0.42039,     0.41942,     0.41651,     0.41591,     0.41329,     0.41105,     0.41029,     0.40791,     0.40582,     0.40363,     0.40231,     0.39931,     0.39826,\n",
       "            0.39602,     0.39362,     0.39265,     0.38966,     0.38803,     0.38585,     0.38324,     0.38175,     0.37868,     0.37593,     0.37473,     0.37159,     0.36892,     0.36713,     0.36435,      0.3604,     0.35886,      0.3555,     0.35214,     0.35079,     0.34738,     0.34358,     0.33958,\n",
       "            0.33686,     0.33342,     0.32947,     0.32501,     0.32324,     0.32033,     0.31668,     0.31266,     0.30878,     0.30494,     0.30279,     0.29782,     0.29285,     0.28817,     0.28466,     0.28071,     0.27633,     0.27173,     0.26931,     0.26529,     0.26039,     0.25623,     0.25162,\n",
       "            0.24673,     0.24103,     0.23635,      0.2313,     0.22655,     0.22107,      0.2161,     0.21223,     0.20653,     0.19776,     0.19287,     0.18863,     0.18482,     0.18037,     0.17657,     0.17225,     0.16801,     0.16334,      0.1591,     0.15515,     0.15033,     0.14243,     0.13856,\n",
       "            0.13512,     0.13015,     0.12643,     0.12226,     0.11809,     0.10801,     0.10187,    0.089601,    0.083098,    0.078201,    0.073596,    0.069357,     0.06126,    0.058395,    0.054448,    0.050501,    0.044436,    0.041292,    0.038513,    0.033616,    0.031495,    0.029154,    0.024915,\n",
       "           0.021698,    0.019722,    0.017016,    0.013726,    0.012156,   0.0098485,   0.0086033,   0.0065637,    0.006186,   0.0057442,   0.0042799,   0.0037448,   0.0031771,   0.0028083,   0.0024395,   0.0021437,    0.001994,   0.0018443,   0.0014025,   0.0011376,     0.00103,  0.00095136,  0.00054787,\n",
       "         0.00036347,  0.00029037,  0.00025294,  0.00020476,  0.00013306,  0.00011167,  9.0282e-05,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.639939799580104\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.62146])\n",
       "names: {0: 'car'}\n",
       "nt_per_class: array([13693])\n",
       "nt_per_image: array([6675])\n",
       "results_dict: {'metrics/precision(B)': 0.8472454263090525, 'metrics/recall(B)': 0.7282929244880606, 'metrics/mAP50(B)': 0.8062620837811011, 'metrics/mAP50-95(B)': 0.6214595457799933, 'fitness': 0.639939799580104}\n",
       "speed: {'preprocess': 0.07649914720810755, 'inference': 0.6433772957754716, 'loss': 7.857544145334079e-05, 'postprocess': 3.010865601986535}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('runs/train-ghost/yolov8-ghostp2-optimized3/weights/last.pt')\n",
    "\n",
    "# Resume training\n",
    "model.train(\n",
    "    resume=True,  # THIS is critical\n",
    "    device=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (2637243109.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 39\u001b[0;36m\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8-ghost-p2.yaml')\n",
    "\n",
    "model.train(\n",
    "    data='data.yaml',\n",
    "    evolve,\n",
    "    epochs=200,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.0001,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    cos_lr=True,\n",
    "    warmup_epochs=3,\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=0.0,\n",
    "    perspective=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    "    copy_paste=0.1,\n",
    "    workers=8,\n",
    "    device=1,\n",
    "    patience=10,\n",
    "    project='runs/evolve-last',\n",
    "    name='evolve-ghostp2',\n",
    "    cache=True\n",
    "       # This works ONLY in Python API\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
