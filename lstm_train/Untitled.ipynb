{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76aaae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   9%|▉         | 7802/83791 [01:25<13:57, 90.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_idx, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(image_paths, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing frames\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     78\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 80\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrack(\n\u001b[1;32m     82\u001b[0m         frame,\n\u001b[1;32m     83\u001b[0m         tracker\u001b[38;5;241m=\u001b[39mTRACKER_CONFIG,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     89\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mboxes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "# --- Config ---\n",
    "IMAGE_DIR = \"/workspace/hjs/python/UA-DETRAC_UPD_ANN/images/train\"\n",
    "MODEL_PATH = \"yolov8n.pt\"\n",
    "TRACKER_CONFIG = \"bytetrack.yaml\"\n",
    "HOMOGRAPHY_PATH = \"/workspace/hjs/python/temp/homography.npy\"\n",
    "OUTPUT_PATH = \"car_trajectories2.pkl\"\n",
    "TARGET_CLASS = \"car\"\n",
    "CONF_THRESHOLD = 0.3\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "# --- Check for GPU ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Load homography ---\n",
    "H = np.load(HOMOGRAPHY_PATH).astype(np.float32)\n",
    "def img_to_world(pt):\n",
    "    px = np.array([pt[0], pt[1], 1.0], dtype=np.float32)\n",
    "    wx = np.dot(H, px)\n",
    "    wx /= wx[2]\n",
    "    return wx[0], wx[1]\n",
    "\n",
    "# --- Simple Kalman filter (constant velocity) ---\n",
    "class KalmanFilter:\n",
    "    def __init__(self, x, y):\n",
    "        self.state = np.array([x, y, 0, 0], dtype='float32')\n",
    "        self.P = np.eye(4) * 500\n",
    "        dt = 1\n",
    "        self.F = np.array([[1, 0, dt, 0],\n",
    "                           [0, 1, 0, dt],\n",
    "                           [0, 0, 1,  0],\n",
    "                           [0, 0, 0,  1]], dtype='float32')\n",
    "        self.H = np.array([[1, 0, 0, 0],\n",
    "                           [0, 1, 0, 0]], dtype='float32')\n",
    "        self.Q = np.eye(4) * 0.01\n",
    "        self.R = np.eye(2) * 0.1\n",
    "\n",
    "    def update(self, x, y):\n",
    "        self.state = self.F @ self.state\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "        z = np.array([x, y], dtype=np.float32)\n",
    "        y_ = z - self.H @ self.state\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
    "        self.state += K @ y_\n",
    "        self.P = (np.eye(4) - K @ self.H) @ self.P\n",
    "        return self.state[0], self.state[1]\n",
    "\n",
    "# --- Load YOLO model (Ultralytics uses GPU automatically) ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# --- Get class ID for 'car' ---\n",
    "class_names = model.model.names\n",
    "target_class_id = [i for i, name in class_names.items() if name.lower() == TARGET_CLASS.lower()]\n",
    "if not target_class_id:\n",
    "    raise ValueError(f\"Class '{TARGET_CLASS}' not found in model classes.\")\n",
    "target_class_id = target_class_id[0]\n",
    "\n",
    "# --- Load image paths ---\n",
    "image_paths = sorted(glob.glob(os.path.join(IMAGE_DIR, \"*.jpg\")))\n",
    "fps = 25  # UA-DETRAC default\n",
    "kalman_filters = {}\n",
    "vehicle_trajectories = {}\n",
    "track_last_seen = {}\n",
    "\n",
    "# --- Process each frame with progress bar ---\n",
    "for frame_idx, path in enumerate(tqdm(image_paths, desc=\"Processing frames\")):\n",
    "    start_time = time.time()\n",
    "\n",
    "    frame = cv2.imread(path)\n",
    "    results = model.track(\n",
    "        frame,\n",
    "        tracker=TRACKER_CONFIG,\n",
    "        persist=True,\n",
    "        conf=CONF_THRESHOLD,\n",
    "        iou=IOU_THRESHOLD,\n",
    "        verbose=False,\n",
    "        device=device\n",
    "    )[0]\n",
    "\n",
    "    if results.boxes is None:\n",
    "        continue\n",
    "\n",
    "    for box in results.boxes:\n",
    "        cls_id = int(box.cls[0].item())\n",
    "        conf = box.conf[0].item()\n",
    "        if cls_id != target_class_id or conf < CONF_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "        track_id = int(box.id[0].item()) if box.id is not None else -1\n",
    "        cx, cy = (x1 + x2) // 2, int(y2)\n",
    "\n",
    "        if track_id not in kalman_filters:\n",
    "            kalman_filters[track_id] = KalmanFilter(cx, cy)\n",
    "        smoothed_cx, smoothed_cy = kalman_filters[track_id].update(cx, cy)\n",
    "\n",
    "        wx, wy = img_to_world((smoothed_cx, smoothed_cy))\n",
    "        vehicle_trajectories.setdefault(track_id, []).append((frame_idx, wx, wy))\n",
    "        track_last_seen[track_id] = frame_idx\n",
    "\n",
    "    # Remove stale tracks\n",
    "    for tid in list(track_last_seen):\n",
    "        if frame_idx - track_last_seen[tid] > 30:\n",
    "            track_last_seen.pop(tid)\n",
    "            kalman_filters.pop(tid)\n",
    "\n",
    "    # Optional: Print time per frame\n",
    "    elapsed = time.time() - start_time\n",
    "#     print(f\"Processed frame {frame_idx + 1}/{len(image_paths)} in {elapsed:.2f} sec\", end='\\r')\n",
    "\n",
    "# --- Final report ---\n",
    "print(f\"\\nCollected {len(vehicle_trajectories)} tracks\")\n",
    "\n",
    "# --- Filter short tracks ---\n",
    "min_length = 5\n",
    "vehicle_trajectories = {\n",
    "    k: v for k, v in vehicle_trajectories.items() if len(v) >= min_length\n",
    "}\n",
    "\n",
    "# --- Save to file ---\n",
    "with open(OUTPUT_PATH, \"wb\") as f:\n",
    "    pickle.dump(vehicle_trajectories, f)\n",
    "\n",
    "print(f\"Saved {len(vehicle_trajectories)} valid trajectories to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4dee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unloaded\n",
      "Prepared dataset: X=(609284, 10, 2), Y=(609284, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Load data ---\n",
    "with open(\"car_trajectories.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "print('unloaded')\n",
    "# --- Parameters ---\n",
    "input_len = 10   # use past 10 positions\n",
    "pred_len = 5     # predict next 5 positions\n",
    "\n",
    "X_seqs = []\n",
    "Y_seqs = []\n",
    "\n",
    "for track_id, points in data.items():\n",
    "    coords = np.array([[p[1], p[2]] for p in points])  # drop frame index\n",
    "    if len(coords) < input_len + pred_len:\n",
    "        continue\n",
    "    for i in range(len(coords) - input_len - pred_len + 1):\n",
    "        input_seq = coords[i:i+input_len]\n",
    "        pred_seq = coords[i+input_len:i+input_len+pred_len]\n",
    "        X_seqs.append(input_seq)\n",
    "        Y_seqs.append(pred_seq)\n",
    "\n",
    "X = np.array(X_seqs)  # (N, 10, 2)\n",
    "Y = np.array(Y_seqs)  # (N, 5, 2)\n",
    "\n",
    "print(f\"Prepared dataset: X={X.shape}, Y={Y.shape}\")\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3101e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared dataset: X=(609284, 10, 2), Y=(609284, 5, 2)\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Load trajectory data ---\n",
    "with open(\"car_trajectories.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# --- Parameters ---\n",
    "input_len = 10\n",
    "pred_len = 5\n",
    "X_seqs, Y_seqs = [], []\n",
    "\n",
    "for track_id, points in data.items():\n",
    "    coords = np.array([[p[1], p[2]] for p in points])  # remove frame index\n",
    "    if len(coords) < input_len + pred_len:\n",
    "        continue\n",
    "    for i in range(len(coords) - input_len - pred_len + 1):\n",
    "        X_seqs.append(coords[i:i+input_len])\n",
    "        Y_seqs.append(coords[i+input_len:i+input_len+pred_len])\n",
    "\n",
    "X = np.array(X_seqs)  # shape: [N, 10, 2]\n",
    "Y = np.array(Y_seqs)  # shape: [N, 5, 2]\n",
    "print(f\"Prepared dataset: X={X.shape}, Y={Y.shape}\")\n",
    "\n",
    "# --- Train/Val Split ---\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- GPU ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- DataLoaders ---\n",
    "BATCH_SIZE = 64\n",
    "train_ds = TensorDataset(torch.Tensor(X_train), torch.Tensor(Y_train))\n",
    "val_ds = TensorDataset(torch.Tensor(X_val), torch.Tensor(Y_val))\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "# --- GRU Model ---\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=64, num_layers=1, output_len=5, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_len * 2)\n",
    "\n",
    "    def forward(self, x):  # x: [B, 10, 2]\n",
    "        _, hn = self.gru(x)              # hn: [num_layers, B, hidden]\n",
    "        out = self.fc(hn[-1])            # out: [B, output_len * 2]\n",
    "        return out.view(-1, 5, 2)        # reshape to [B, 5, 2]\n",
    "\n",
    "model = GRU().to(device)\n",
    "\n",
    "# --- Optimizer, Loss ---\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# --- Custom velocity loss ---\n",
    "def velocity_loss(pred, target):\n",
    "    pred_vel = pred[:, 1:] - pred[:, :-1]\n",
    "    target_vel = target[:, 1:] - target[:, :-1]\n",
    "    return nn.functional.mse_loss(pred_vel, target_vel)\n",
    "\n",
    "# --- Evaluation Metrics ---\n",
    "def compute_metrics(pred, target):\n",
    "    ade = torch.mean(torch.norm(pred - target, dim=2))  # average displacement error\n",
    "    fde = torch.mean(torch.norm(pred[:, -1] - target[:, -1], dim=1))  # final displacement error\n",
    "    mae = torch.mean(torch.abs(pred - target))\n",
    "    return ade.item(), fde.item(), mae.item()\n",
    "\n",
    "# --- Training Loop ---\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "epochs_without_improvement = 0\n",
    "checkpoint_path = 'best_gru_model.pt'\n",
    "EPOCHS = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6a9c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Epoch 1/100 ---\n",
      "Epoch 1 - Train Loss: 0.3056, Val Loss: 0.0173 | ADE: 0.1212, FDE: 0.1544, MAE: 0.0694\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 2/100 ---\n",
      "Epoch 2 - Train Loss: 0.0115, Val Loss: 0.0115 | ADE: 0.0678, FDE: 0.1027, MAE: 0.0420\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 3/100 ---\n",
      "Epoch 3 - Train Loss: 0.0107, Val Loss: 0.0124 | ADE: 0.0860, FDE: 0.1166, MAE: 0.0498\n",
      "⚠️  No improvement. 1 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 4/100 ---\n",
      "Epoch 4 - Train Loss: 0.0098, Val Loss: 0.0099 | ADE: 0.0665, FDE: 0.0890, MAE: 0.0390\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 5/100 ---\n",
      "Epoch 5 - Train Loss: 0.0092, Val Loss: 0.0087 | ADE: 0.0470, FDE: 0.0735, MAE: 0.0276\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 6/100 ---\n",
      "Epoch 6 - Train Loss: 0.0088, Val Loss: 0.0098 | ADE: 0.0650, FDE: 0.1044, MAE: 0.0368\n",
      "⚠️  No improvement. 1 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 7/100 ---\n",
      "Epoch 7 - Train Loss: 0.0086, Val Loss: 0.0092 | ADE: 0.0506, FDE: 0.0782, MAE: 0.0292\n",
      "⚠️  No improvement. 2 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 8/100 ---\n",
      "Epoch 8 - Train Loss: 0.0084, Val Loss: 0.0087 | ADE: 0.0475, FDE: 0.0742, MAE: 0.0281\n",
      "⚠️  No improvement. 3 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 9/100 ---\n",
      "Epoch 9 - Train Loss: 0.0077, Val Loss: 0.0083 | ADE: 0.0488, FDE: 0.0726, MAE: 0.0294\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 10/100 ---\n",
      "Epoch 10 - Train Loss: 0.0075, Val Loss: 0.0082 | ADE: 0.0471, FDE: 0.0720, MAE: 0.0271\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 11/100 ---\n",
      "Epoch 11 - Train Loss: 0.0073, Val Loss: 0.0088 | ADE: 0.0455, FDE: 0.0710, MAE: 0.0263\n",
      "⚠️  No improvement. 1 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 12/100 ---\n",
      "Epoch 12 - Train Loss: 0.0072, Val Loss: 0.0084 | ADE: 0.0482, FDE: 0.0736, MAE: 0.0273\n",
      "⚠️  No improvement. 2 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 13/100 ---\n",
      "Epoch 13 - Train Loss: 0.0072, Val Loss: 0.0081 | ADE: 0.0490, FDE: 0.0748, MAE: 0.0281\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 14/100 ---\n",
      "Epoch 14 - Train Loss: 0.0070, Val Loss: 0.0091 | ADE: 0.0644, FDE: 0.1005, MAE: 0.0373\n",
      "⚠️  No improvement. 1 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 15/100 ---\n",
      "Epoch 15 - Train Loss: 0.0069, Val Loss: 0.0082 | ADE: 0.0508, FDE: 0.0709, MAE: 0.0299\n",
      "⚠️  No improvement. 2 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 16/100 ---\n",
      "Epoch 16 - Train Loss: 0.0069, Val Loss: 0.0082 | ADE: 0.0511, FDE: 0.0764, MAE: 0.0299\n",
      "⚠️  No improvement. 3 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 17/100 ---\n",
      "Epoch 17 - Train Loss: 0.0065, Val Loss: 0.0076 | ADE: 0.0440, FDE: 0.0677, MAE: 0.0249\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 18/100 ---\n",
      "Epoch 18 - Train Loss: 0.0064, Val Loss: 0.0077 | ADE: 0.0438, FDE: 0.0675, MAE: 0.0249\n",
      "⚠️  No improvement. 1 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 19/100 ---\n",
      "Epoch 19 - Train Loss: 0.0064, Val Loss: 0.0076 | ADE: 0.0439, FDE: 0.0676, MAE: 0.0251\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 20/100 ---\n",
      "Epoch 20 - Train Loss: 0.0063, Val Loss: 0.0078 | ADE: 0.0459, FDE: 0.0688, MAE: 0.0265\n",
      "⚠️  No improvement. 1 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 21/100 ---\n",
      "Epoch 21 - Train Loss: 0.0063, Val Loss: 0.0076 | ADE: 0.0435, FDE: 0.0679, MAE: 0.0247\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 22/100 ---\n",
      "Epoch 22 - Train Loss: 0.0063, Val Loss: 0.0076 | ADE: 0.0451, FDE: 0.0689, MAE: 0.0267\n",
      "⚠️  No improvement. 1 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 23/100 ---\n",
      "Epoch 23 - Train Loss: 0.0061, Val Loss: 0.0075 | ADE: 0.0430, FDE: 0.0667, MAE: 0.0247\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 24/100 ---\n",
      "Epoch 24 - Train Loss: 0.0060, Val Loss: 0.0075 | ADE: 0.0432, FDE: 0.0672, MAE: 0.0248\n",
      "✔️  New best model saved.\n",
      "\n",
      "--- Starting Epoch 25/100 ---\n",
      "Epoch 25 - Train Loss: 0.0060, Val Loss: 0.0078 | ADE: 0.0447, FDE: 0.0704, MAE: 0.0253\n",
      "⚠️  No improvement. 1 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 26/100 ---\n",
      "Epoch 26 - Train Loss: 0.0060, Val Loss: 0.0076 | ADE: 0.0428, FDE: 0.0668, MAE: 0.0244\n",
      "⚠️  No improvement. 2 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 27/100 ---\n",
      "Epoch 27 - Train Loss: 0.0060, Val Loss: 0.0075 | ADE: 0.0429, FDE: 0.0674, MAE: 0.0243\n",
      "⚠️  No improvement. 3 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 28/100 ---\n",
      "Epoch 28 - Train Loss: 0.0059, Val Loss: 0.0076 | ADE: 0.0431, FDE: 0.0670, MAE: 0.0246\n",
      "⚠️  No improvement. 4 epochs without improvement.\n",
      "\n",
      "--- Starting Epoch 29/100 ---\n",
      "Epoch 29 - Train Loss: 0.0059, Val Loss: 0.0075 | ADE: 0.0424, FDE: 0.0659, MAE: 0.0241\n",
      "⚠️  No improvement. 5 epochs without improvement.\n",
      "⏹️ Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "epochs_without_improvement = 0\n",
    "checkpoint_path = 'best_gru_model.pt'\n",
    "EPOCHS = 100  # Set higher, since early stopping will control actual training duration\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n--- Starting Epoch {epoch + 1}/{EPOCHS} ---\")\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = mse_loss(pred, yb) + 0.1 * velocity_loss(pred, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, ade, fde, mae = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = mse_loss(pred, yb) + 0.1 * velocity_loss(pred, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "            batch_ade, batch_fde, batch_mae = compute_metrics(pred, yb)\n",
    "            ade += batch_ade * xb.size(0)\n",
    "            fde += batch_fde * xb.size(0)\n",
    "            mae += batch_mae * xb.size(0)\n",
    "\n",
    "    train_loss /= len(train_dl.dataset)\n",
    "    val_loss /= len(val_dl.dataset)\n",
    "    ade /= len(val_dl.dataset)\n",
    "    fde /= len(val_dl.dataset)\n",
    "    mae /= len(val_dl.dataset)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} | \"\n",
    "          f\"ADE: {ade:.4f}, FDE: {fde:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "    # --- Early Stopping Check ---\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(\"✔️  New best model saved.\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"⚠️  No improvement. {epochs_without_improvement} epochs without improvement.\")\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"⏹️ Early stopping triggered.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e55d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
